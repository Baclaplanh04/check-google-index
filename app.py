import streamlit as st
import pandas as pd
import requests
import time
import re
from io import BytesIO
from datetime import datetime
from urllib.parse import quote_plus

# =============== C·∫§U H√åNH GIAO DI·ªÜN ===============
st.set_page_config(page_title="Ki·ªÉm tra Google Index - Profile", layout="centered")

st.title("üïµÔ∏è‚Äç‚ôÇÔ∏è Ki·ªÉm tra Google Index cho danh s√°ch Profile")
st.markdown("""
·ª®ng d·ª•ng n√†y gi√∫p b·∫°n ki·ªÉm tra xem c√°c URL trong file Excel c√≥ ƒë∆∞·ª£c Google index hay kh√¥ng,  
v√† n·∫øu c√≥ th√¨ c√≥ **index trong 30 ng√†y qua** hay kh√¥ng.
""")

# =============== UPLOAD FILE ===============
uploaded_file = st.file_uploader("üì§ T·∫£i l√™n file Excel (.xlsx)", type=["xlsx"])

# =============== C√ÄI ƒê·∫∂T ===============
st.sidebar.header("‚öôÔ∏è C√†i ƒë·∫∑t ki·ªÉm tra")
delay = st.sidebar.number_input("‚è± Delay gi·ªØa m·ªói l·∫ßn ki·ªÉm tra (gi√¢y)", min_value=0.5, value=2.0, step=0.5)
limit_urls = st.sidebar.number_input("üî¢ Gi·ªõi h·∫°n s·ªë URL ki·ªÉm tra", min_value=1, value=1000, step=1)
user_agent = st.sidebar.selectbox("üß≠ Ch·ªçn User-Agent", [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 Chrome/118.0 Safari/537.36",
])
headers = {"User-Agent": user_agent}


# =============== H√ÄM KI·ªÇM TRA INDEX ===============
def is_indexed(url, headers):
    """Ki·ªÉm tra xem URL c√≥ ƒë∆∞·ª£c Google index hay kh√¥ng (ch√≠nh x√°c h∆°n)."""
    query = f"site:{url}"
    try:
        resp = requests.get("https://www.google.com/search?q=" + quote_plus(query), headers=headers, timeout=20)
        html = resp.text.lower()
    except Exception as e:
        return False, f"L·ªói request: {e}"

    # Ki·ªÉm tra CAPTCHA / ch·∫∑n t·∫°m th·ªùi
    if "unusual traffic" in html or "recaptcha" in html:
        return False, "‚ö†Ô∏è Google ch·∫∑n truy c·∫≠p t·∫°m th·ªùi (CAPTCHA)."

    # N·∫øu c√≥ kh·ªëi k·∫øt qu·∫£ t√¨m ki·∫øm -> coi nh∆∞ c√≥ index
    if re.search(r'class="g"|id="search"|k·∫øt qu·∫£|about [\d,]+ results|c√≥ kho·∫£ng', html):
        return True, html

    # N·∫øu c√≥ th√¥ng b√°o kh√¥ng c√≥ k·∫øt qu·∫£
    if "did not match any documents" in html or "no results found" in html or "kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£" in html:
        return False, html

    # Tr∆∞·ªùng h·ª£p m·∫∑c ƒë·ªãnh
    return False, html


def google_cache_date(url, headers):
    """L·∫•y ng√†y cached page t·ª´ Google (n·∫øu c√≥)."""
    q = f"cache:{url}"
    try:
        r = requests.get("https://www.google.com/search?q=" + quote_plus(q), headers=headers, timeout=20)
        text = r.text
    except:
        return None

    match = re.search(
        r"As it appeared on (\w+ \d{1,2}, \d{4})|L∆∞u trong b·ªô nh·ªõ cache.*?(\d{1,2}) th√°ng (\d{1,2}), (\d{4})",
        text, re.I
    )
    if match:
        try:
            if match.group(1):
                return datetime.strptime(match.group(1), "%B %d, %Y").strftime("%d/%m/%Y")
            else:
                d, m, y = match.group(2), match.group(3), match.group(4)
                return f"{int(d):02d}/{int(m):02d}/{y}"
        except:
            return None
    return None


# =============== X·ª¨ L√ù FILE EXCEL ===============
if uploaded_file:
    header_row = st.number_input("üìÑ D√≤ng ch·ª©a ti√™u ƒë·ªÅ (v√≠ d·ª•: 1 ho·∫∑c 3)", min_value=1, value=1, step=1)
    try:
        df = pd.read_excel(uploaded_file, header=header_row - 1)
    except Exception as e:
        st.error(f"L·ªói ƒë·ªçc file Excel: {e}")
        st.stop()

    # T√¨m c·ªôt ch·ª©a URL (Profile/URL/Link)
    col_candidates = [c for c in df.columns if re.search(r'profile|url|link', str(c), re.I)]
    if not col_candidates:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt ch·ª©a URL (v√≠ d·ª•: Profile, URL, Link). Vui l√≤ng ki·ªÉm tra l·∫°i file Excel.")
        st.stop()

    col_name = col_candidates[0]
    profiles = df[col_name].dropna().tolist()[:limit_urls]

    if not profiles:
        st.error("Kh√¥ng c√≥ URL n√†o trong file Excel.")
        st.stop()

    st.success(f"T√¨m th·∫•y {len(profiles)} URL. (S·∫Ω ki·ªÉm tra t·ªëi ƒëa {limit_urls} URL.)")

    # =============== CH·∫†Y KI·ªÇM TRA ===============
    results = []
    progress = st.progress(0)
    status_text = st.empty()

    for i, url in enumerate(profiles):
        status_text.text(f"üîç ƒêang ki·ªÉm tra {i+1}/{len(profiles)}: {url}")
        try:
            indexed, html = is_indexed(url, headers)
            cache_date = google_cache_date(url, headers) if indexed else None
            results.append({
                "URL": url,
                "ƒê√£ Index": "‚úÖ C√≥" if indexed else "‚ùå Kh√¥ng",
                "Ng√†y Cache": cache_date if cache_date else "-"
            })
        except Exception as e:
            results.append({"URL": url, "ƒê√£ Index": "‚ö†Ô∏è L·ªói", "Ng√†y Cache": str(e)})
        progress.progress((i + 1) / len(profiles))
        time.sleep(delay)

    # =============== HI·ªÇN TH·ªä K·∫æT QU·∫¢ ===============
    st.subheader("üìä K·∫øt qu·∫£ ki·ªÉm tra")
    result_df = pd.DataFrame(results)
    st.dataframe(result_df, use_container_width=True)

    # Xu·∫•t file Excel
    output = BytesIO()
    result_df.to_excel(output, index=False)
    st.download_button(
        label="üì• T·∫£i k·∫øt qu·∫£ v·ªÅ (.xlsx)",
        data=output.getvalue(),
        file_name="ket_qua_google_index.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

st.sidebar.markdown("---")
st.sidebar.info("üí° M·∫πo: N·∫øu b·ªã b√°o 'Kh√¥ng c√≥ URL', h√£y ki·ªÉm tra l·∫°i d√≤ng ti√™u ƒë·ªÅ ho·∫∑c t√™n c·ªôt (Profile/URL/Link).")
